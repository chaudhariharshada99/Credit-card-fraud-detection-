{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Case Study On Credit Card Fraud Detection Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"E:\\\\ITVedanta\\\\Machine Learning\\\\Project ML\\\\creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=df,x=\"Class\")\n",
    "c=df[\"Class\"].value_counts()\n",
    "plt.yticks(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Observation:** \n",
    "    - Data is heavily imbalced here.\n",
    "    - Class '0' has 284315 records and class'1' has only 492 records.\n",
    "    - Here, class '0' is for No Fraud and class '1' is for Fraud records.\n",
    "    - Data should be atleast 50-50 % distributed when we are predicting between yes and no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate input and output variable:\n",
    "X=df.drop(\"Class\",axis=1) #input variable\n",
    "Y=df[\"Class\"] #Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting dataset 70% - 30%\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model\n",
    "def create_model(model):\n",
    "    model.fit(X_train1,Y_train1)\n",
    "    Y_pred=model.predict(X_test1)\n",
    "    print(classification_report(Y_test1,Y_pred))\n",
    "    print(\"Confusion Matrix :\")\n",
    "    #Confusion matrix\n",
    "    print(confusion_matrix(Y_test1,Y_pred))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of LogisticRegression class\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9989934810341398"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_prediction=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85308\n",
      "           1       0.71      0.62      0.66       135\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.85      0.81      0.83     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basemodel Logistic regression\n",
    "print(classification_report(Y_test,Y_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Observation:** \n",
    "    - In above report '0' has given perfect score but '1' has given bad results as it has lesser samples or imbalanced samples as compare to '0'.\n",
    "    - '0' has - 100% recall score and '1' has 62% recall score.\n",
    "    - This dataset has intention to detect fraud so we need to focus on '1' score.\n",
    "    - Lets balance the dataset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVER SAMPLER:\n",
    "ros = RandomOverSampler() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199007\n",
       "1       357\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before apply randomoversampler\n",
    "pd.Series(Y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply randomundersampling for balance\n",
    "X_train1,Y_train1=ros.fit_resample(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    199007\n",
       "0    199007\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after apply randomoversampler\n",
    "pd.Series(Y_train1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create object of LogisticRegression class\n",
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    85308\n",
       "1      135\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before apply randomoversampler ,check Y_test\n",
    "pd.Series(Y_test).value_counts() #check if not balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply randomoversampling for balance\n",
    "X_test1,Y_test1=ros.fit_resample(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    85308\n",
       "0    85308\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after apply randomoversampler\n",
    "pd.Series(Y_test1).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.92     85308\n",
      "           1       0.97      0.87      0.91     85308\n",
      "\n",
      "    accuracy                           0.92    170616\n",
      "   macro avg       0.92      0.92      0.92    170616\n",
      "weighted avg       0.92      0.92      0.92    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[82826  2482]\n",
      " [11310 73998]]\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression Oversampling\n",
    "lr=create_model(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **OBSERVATION AFTER OVERSAMPLING in LogisticRegression**\n",
    "    - This score report is better than report before sampling.\n",
    "    - Class '0' - 97%  and  class '1' - 87%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object of DecisionTreeClassifier class\n",
    "dt=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.87     85308\n",
      "           1       1.00      0.69      0.82     85308\n",
      "\n",
      "    accuracy                           0.85    170616\n",
      "   macro avg       0.88      0.85      0.84    170616\n",
      "weighted avg       0.88      0.85      0.84    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[85276    32]\n",
      " [26267 59041]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier with Over sampling\n",
    "dt=create_model(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **OBSERVATION AFTER OVERSAMPLING in Decision Tree Classifier**\n",
    "    - This score report is better than report before sampling, Logistic Regression and over sampling technique also.\n",
    "    - Class '0' - 87%  and  class '1' - 92% \n",
    "    - Lets check if our model has overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score :  1.0\n"
     ]
    }
   ],
   "source": [
    "# Checking training score\n",
    "training_score=dt.score(X_train1,Y_train1)\n",
    "print(\"Training Score : \",training_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Score :  0.845858536127913\n"
     ]
    }
   ],
   "source": [
    "# Checking testing score\n",
    "testing_score=dt.score(X_test1,Y_test1)\n",
    "print(\"Testing Score : \",testing_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see training score > testing score means under sampled DTC model has overfitting.\n",
    "- To remove overfitting, lets apply pruning techniques.\n",
    "### 1. max_depth (Pruning Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object of DecisionTreeClassifier class and passing the parameter\n",
    "#max_depth\n",
    "dt1=DecisionTreeClassifier(max_depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91     85308\n",
      "           1       0.99      0.82      0.90     85308\n",
      "\n",
      "    accuracy                           0.91    170616\n",
      "   macro avg       0.92      0.91      0.91    170616\n",
      "weighted avg       0.92      0.91      0.91    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[84390   918]\n",
      " [14995 70313]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier (max_depth pruning technique) with oversampling \n",
    "dt1=create_model(dt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using max_depth pruning technique, we are getting less recall score for 'fraudulent records', than DTC under sampled model. \n",
    "- Now check another pruning technique.\n",
    "### 2. min_samples_leaf: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create object of DecisionTreeClassifier for min_sample_leaf class\n",
    "dt2=DecisionTreeClassifier(min_samples_leaf=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92     85308\n",
      "           1       1.00      0.82      0.90     85308\n",
      "\n",
      "    accuracy                           0.91    170616\n",
      "   macro avg       0.92      0.91      0.91    170616\n",
      "weighted avg       0.92      0.91      0.91    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[85094   214]\n",
      " [15121 70187]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier (min_samples_leaf pruning technique) with oversampling \n",
    "dt2=create_model(dt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using min_sample_leaf pruning technique also, we are getting less recall score for 'fraudulent records', than DTC under sampled model.\n",
    "- So, we are concluding that, the model was not overfit.\n",
    "- Lets use seom Feature selection methods and check if we can improve scores.\n",
    "\n",
    "## Feature Selection:\n",
    "### 1. Wrapper- A) Forward method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column :  Time  Score :  0.9984199992977775\n",
      "Column :  V1  Score :  0.9982795547909132\n",
      "Column :  V2  Score :  0.9984551104244935\n",
      "Column :  V3  Score :  0.9983614807532507\n",
      "Column :  V4  Score :  0.9987828142738434\n",
      "Column :  V5  Score :  0.9988062216916541\n",
      "Column :  V6  Score :  0.9986189623491685\n",
      "Column :  V7  Score :  0.9986540734758845\n",
      "Column :  V8  Score :  0.9985721475135471\n",
      "Column :  V9  Score :  0.997940147232658\n",
      "Column :  V10  Score :  0.9974251840408226\n",
      "Column :  V11  Score :  0.9975539248387814\n",
      "Column :  V12  Score :  0.9980571843217115\n",
      "Column :  V13  Score :  0.9983263696265346\n",
      "Column :  V14  Score :  0.9988647402361809\n",
      "Column :  V15  Score :  0.9988881476539916\n",
      "Column :  V16  Score :  0.9989583699074237\n",
      "Column :  V17  Score :  0.998934962489613\n",
      "Column :  V18  Score :  0.9990285921608558\n",
      "Column :  V19  Score :  0.9982561473731025\n",
      "Column :  V20  Score :  0.9988647402361809\n",
      "Column :  V21  Score :  0.9983263696265346\n",
      "Column :  V22  Score :  0.9990637032875719\n",
      "Column :  V23  Score :  0.9990519995786665\n",
      "Column :  V24  Score :  0.9990637032875719\n",
      "Column :  V25  Score :  0.9988998513628969\n",
      "Column :  V26  Score :  0.9988764439450862\n",
      "Column :  V27  Score :  0.9989583699074237\n",
      "Column :  V28  Score :  0.9990754069964772\n",
      "Column :  Amount  Score :  0.9989934810341398\n"
     ]
    }
   ],
   "source": [
    "columns=[] #columns is the user defined list object\n",
    "for col in X:\n",
    "    #print(col)\n",
    "    columns.append(col)\n",
    "    #print(columns)\n",
    "    X_new=df[columns] #new input\n",
    "    #call train_test_split()\n",
    "    X_train,X_test,Y_train,Y_test = train_test_split(X_new,Y,test_size=0.3,random_state=1)\n",
    "    #create object of LinearRegression class\n",
    "    lr=LogisticRegression()\n",
    "    #train the model\n",
    "    lr.fit(X_train,Y_train)\n",
    "    #find score\n",
    "    score=lr.score(X_test,Y_test)\n",
    "    print(\"Column : \",col,\" Score : \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Observation: for Forward Wrapping Method**\n",
    "    - Cannot conclude which features are important as there is No significant change has found for any feature.\n",
    "    - Here we are getting score 99% for entire input features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "### 2.Feature Selection by PCA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create object of PCA\n",
    "pc=PCA(n_components=18,random_state=1)#n_components : how many principal components\n",
    "X_train_pc=pc.fit_transform(X_train1,Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pc=pc.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_pc,Y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.885807896094153"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test_pc,Y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Observation of PCA after balancing and reforming dataset:**\n",
    "\n",
    "\n",
    "    - We got highest score at n_estimator value 18, which is 0.9.\n",
    "    - But if we see carefully there is not a significant change in scores after 13 to 29.\n",
    "    - So for now keeping all features as input records.\n",
    "    \n",
    "    \n",
    "- **Till now we have the highest score of module of DTC(under sampling)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling technique \n",
    "### 1. Naive Aggregation\n",
    "##### a) Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First take logistic regreesion \n",
    "# create object of Logistic Regression class \n",
    "lr=LogisticRegression()\n",
    "\n",
    "# Second take DecisionTreeClassifier : gini index\n",
    "# Create the object of DecisionTreeClassifier  class\n",
    "dt1=DecisionTreeClassifier() #bydefault method gini index\n",
    "\n",
    "# Third take DecisionTreeClassifier : entropy method\n",
    "# Create the object of DecisionTreeClassifier  class\n",
    "dtE=DecisionTreeClassifier(criterion=\"entropy\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Begin with simple first\n",
    "#create a model list \n",
    "model_list=[(\"Logistic\",lr),(\"Decision_tree_gini\",dt1),\n",
    "            (\"Decision_tree_entropy\",dtE)]\n",
    "#(\"model name\",object of those model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then we need Naive aggregation\n",
    "#we importing class\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object of VotingClassifier class\n",
    "vc=VotingClassifier(estimators=model_list) \n",
    "#bydefault use hardvoting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90     85308\n",
      "           1       1.00      0.79      0.88     85308\n",
      "\n",
      "    accuracy                           0.89    170616\n",
      "   macro avg       0.91      0.89      0.89    170616\n",
      "weighted avg       0.91      0.89      0.89    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[85274    34]\n",
      " [18132 67176]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Hard voting\n",
    "#call create_model()\n",
    "model=create_model(vc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object of VotingClassifier class\n",
    "vc2=VotingClassifier(estimators=model_list,voting=\"soft\") \n",
    "# as voting='hard' is by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90     85308\n",
      "           1       1.00      0.78      0.88     85308\n",
      "\n",
      "    accuracy                           0.89    170616\n",
      "   macro avg       0.91      0.89      0.89    170616\n",
      "weighted avg       0.91      0.89      0.89    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[85280    28]\n",
      " [18760 66548]]\n"
     ]
    }
   ],
   "source": [
    "# Naive soft voting\n",
    "#call create_model()\n",
    "model=create_model(vc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bootstrapping:\n",
    "#### a) Bagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create object of BaggingClassifier class\n",
    "bc= BaggingClassifier(LogisticRegression(),n_estimators=10,max_samples=100,\n",
    "                      random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92     85308\n",
      "           1       0.96      0.88      0.91     85308\n",
      "\n",
      "    accuracy                           0.92    170616\n",
      "   macro avg       0.92      0.92      0.92    170616\n",
      "weighted avg       0.92      0.92      0.92    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[82018  3290]\n",
      " [10659 74649]]\n"
     ]
    }
   ],
   "source": [
    "# Bootstrapping- Bagging - Logistic regression\n",
    "#call function\n",
    "model=create_model(bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create object of BaggingClassifier class\n",
    "bc2= BaggingClassifier(DecisionTreeClassifier(),n_estimators=10,max_samples=520,\n",
    "                      random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92     85308\n",
      "           1       0.98      0.85      0.91     85308\n",
      "\n",
      "    accuracy                           0.92    170616\n",
      "   macro avg       0.92      0.92      0.92    170616\n",
      "weighted avg       0.92      0.92      0.92    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[84076  1232]\n",
      " [13162 72146]]\n"
     ]
    }
   ],
   "source": [
    "# Bootstrapping- Bagging - DTC\n",
    "#call function\n",
    "model=create_model(bc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Pasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create object of BaggingClassifier class\n",
    "bc3= BaggingClassifier(LogisticRegression(),n_estimators=10,max_samples=650,\n",
    "                       random_state=1,bootstrap=False) \n",
    "# bootstrap=False: means pasting \n",
    "# bydefault bootstrap=True means bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     85308\n",
      "           1       0.97      0.87      0.92     85308\n",
      "\n",
      "    accuracy                           0.92    170616\n",
      "   macro avg       0.93      0.92      0.92    170616\n",
      "weighted avg       0.93      0.92      0.92    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[82855  2453]\n",
      " [10713 74595]]\n"
     ]
    }
   ],
   "source": [
    "# Bootstrapping- Pasting - Logistic regression\n",
    "\n",
    "#call function\n",
    "model=create_model(bc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create object of BaggingClassifier class\n",
    "bc4= BaggingClassifier(DecisionTreeClassifier(),n_estimators=10,max_samples=200,\n",
    "                      random_state=1,bootstrap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93     85308\n",
      "           1       0.97      0.88      0.92     85308\n",
      "\n",
      "    accuracy                           0.93    170616\n",
      "   macro avg       0.93      0.93      0.93    170616\n",
      "weighted avg       0.93      0.93      0.93    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[83030  2278]\n",
      " [ 9981 75327]]\n"
     ]
    }
   ],
   "source": [
    "# Bootstrapping- Pasting - DTC\n",
    "\n",
    "#call function\n",
    "model=create_model(bc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Tree:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call Random Forest Tree from package\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the object of RandomForestClassifier class\n",
    "rfc=RandomForestClassifier(n_estimators=5,max_features=5,random_state=1)\n",
    "#max_features not more than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.90     85308\n",
      "           1       1.00      0.77      0.87     85308\n",
      "\n",
      "    accuracy                           0.89    170616\n",
      "   macro avg       0.91      0.89      0.88    170616\n",
      "weighted avg       0.91      0.89      0.88    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[85299     9]\n",
      " [19498 65810]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "model=create_model(rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stacking classifer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call StackingClassifier\n",
    "from mlxtend.classifier import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create object of Logistic Regression ,Decision Tree Entropy and Decision Tree\n",
    "#Gini\n",
    "lr=LogisticRegression()\n",
    "dt1=DecisionTreeClassifier() #bydefault gini index\n",
    "dt2=DecisionTreeClassifier(criterion=\"entropy\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model list\n",
    "model_list=[lr,dt1,dt2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use meta classifier , \n",
    "# select algorithm for meta classifier : LogisticRegression()\n",
    "meta=LogisticRegression() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the objec tof StackingClassifier class and passing the no. of arguments\n",
    "sc=StackingClassifier(classifiers=model_list,meta_classifier=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90     85308\n",
      "           1       1.00      0.79      0.88     85308\n",
      "\n",
      "    accuracy                           0.89    170616\n",
      "   macro avg       0.91      0.89      0.89    170616\n",
      "weighted avg       0.91      0.89      0.89    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[85277    31]\n",
      " [18135 67173]]\n"
     ]
    }
   ],
   "source": [
    "# StackingClassifier\n",
    "#call function\n",
    "model=create_model(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Boosting : \n",
    "### 1. ADA Boost : Adapter boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdaBoostClassifier(n_estimators=35) \n",
    "# n_estimators can be <=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93     85308\n",
      "           1       0.98      0.87      0.92     85308\n",
      "\n",
      "    accuracy                           0.92    170616\n",
      "   macro avg       0.93      0.92      0.92    170616\n",
      "weighted avg       0.93      0.92      0.92    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[83713  1595]\n",
      " [11316 73992]]\n"
     ]
    }
   ],
   "source": [
    "#call function\n",
    "model=create_model(ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Gradient Boosting:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc=GradientBoostingClassifier(n_estimators=30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93     85308\n",
      "           1       0.99      0.87      0.92     85308\n",
      "\n",
      "    accuracy                           0.93    170616\n",
      "   macro avg       0.94      0.93      0.93    170616\n",
      "weighted avg       0.94      0.93      0.93    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[84467   841]\n",
      " [11357 73951]]\n"
     ]
    }
   ],
   "source": [
    "model=create_model(gbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extreame Gradient Boosting  : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg=XGBClassifier(n_estimators=40, reg_alpha=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:28:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91     85308\n",
      "           1       1.00      0.81      0.89     85308\n",
      "\n",
      "    accuracy                           0.90    170616\n",
      "   macro avg       0.92      0.90      0.90    170616\n",
      "weighted avg       0.92      0.90      0.90    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[85284    24]\n",
      " [16262 69046]]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#call function\n",
    "model=create_model(xg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM: Support Vector Machine\n",
    "### 1. Linear Separable data means Linear Kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object of LinearSVC class\n",
    "svc=LinearSVC(random_state=1)  #by default hard margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.89     85308\n",
      "           1       0.99      0.76      0.86     85308\n",
      "\n",
      "    accuracy                           0.87    170616\n",
      "   macro avg       0.90      0.87      0.87    170616\n",
      "weighted avg       0.90      0.87      0.87    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[84540   768]\n",
      " [20665 64643]]\n"
     ]
    }
   ],
   "source": [
    "#call function (for train ,test and print the report)\n",
    "svc=create_model(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=LinearSVC(random_state=1,C=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90     85308\n",
      "           1       0.97      0.81      0.88     85308\n",
      "\n",
      "    accuracy                           0.89    170616\n",
      "   macro avg       0.90      0.89      0.89    170616\n",
      "weighted avg       0.90      0.89      0.89    170616\n",
      "\n",
      "Confusion Matrix :\n",
      "[[82858  2450]\n",
      " [16230 69078]]\n"
     ]
    }
   ],
   "source": [
    "svc=create_model(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
